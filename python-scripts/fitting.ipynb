{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: This script was adapted from HDS-5230, taught in Spring 2019 by Dr. Evan Carey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import sklearn\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original dataset doesn't have column names, so let's go and create them.\n",
    "col_names = ['username','bot_or_not', 'followersCount', 'friendsCount', 'tweetsCount', 'favoritesCount', 'tweetsPerDay', 'followersToFriends', 'favoritesPerTweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets are located at /data/clean/labeled/concatenated/ML folder within this repository\n",
    "data_equal = pd.read_csv('dataset_equal_class.csv', names = col_names) # pass column names as an optional parameter\n",
    "data_all = pd.read_csv('dataset_final.csv', names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1450, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_equal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5042, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bot_or_not ~ tweetsPerDay + friendsCount + favoritesCount + favoritesPerTweet + followersCount + tweetsCount + followersToFriends'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detect variables that we will need for our model\n",
    "vars_to_remove = ['username', 'bot_or_not']\n",
    "vars_left = set(data_equal.columns) - set(vars_to_remove)\n",
    "formula = \"bot_or_not ~ \" + \" + \".join(vars_left)\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Patsy to create design matrices which are sort of enhanced pandas dataframes.\n",
    "Y_all,X_all = dmatrices(formula, data_all)\n",
    "Y_equal,X_equal = dmatrices(formula, data_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_all_normalized = preprocessing.normalize(X_all)\n",
    "X_equal_normalized = preprocessing.normalize(X_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly splitting data into 80/20.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_all_train, X_all_test, y_all_train, y_all_test = \\\n",
    "    train_test_split(X_all,\n",
    "                     np.ravel(Y_all), # prevents dimensionality error later\n",
    "                     test_size=0.2,\n",
    "                     random_state=42)\n",
    "\n",
    "X_equal_train, X_equal_test, y_equal_train, y_equal_test = \\\n",
    "    train_test_split(X_equal,\n",
    "                     np.ravel(Y_equal),\n",
    "                     test_size=0.2,\n",
    "                     random_state=42)\n",
    "\n",
    "X_all_normalized_train, X_all_normalized_test, y_all_normalized_train, y_all_normalized_test = \\\n",
    "    train_test_split(X_all_normalized,\n",
    "                     np.ravel(Y_all),\n",
    "                     test_size=0.2,\n",
    "                     random_state=42)\n",
    "\n",
    "X_equal_normalized_train, X_equal_normalized_test, y_equal_normalized_train, y_equal_normalized_test = \\\n",
    "    train_test_split(X_equal_normalized,\n",
    "                     np.ravel(Y_equal),\n",
    "                     test_size=0.2,\n",
    "                     random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=20, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=1000,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='liblinear',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple logistic regression without regularization.\n",
    "from sklearn import linear_model\n",
    "\n",
    "clf_all = linear_model.LogisticRegressionCV(fit_intercept=True, cv = 5, Cs = 20, solver='liblinear', max_iter = 1000)\n",
    "clf_all.fit(X_all_train,y_all_train)\n",
    "\n",
    "clf_equal = linear_model.LogisticRegressionCV(fit_intercept=True, cv = 5, Cs = 20, solver='liblinear',max_iter = 1000)\n",
    "clf_equal.fit(X_equal_train,y_equal_train)\n",
    "\n",
    "clf_all_normalized = linear_model.LogisticRegressionCV(fit_intercept=True, cv = 5, Cs = 20, solver='liblinear',max_iter = 1000)\n",
    "clf_all_normalized.fit(X_all_normalized_train,y_all_normalized_train)\n",
    "\n",
    "clf_equal_normalized = linear_model.LogisticRegressionCV(fit_intercept=True, cv = 5, Cs = 20, solver='liblinear',max_iter = 1000)\n",
    "clf_equal_normalized.fit(X_equal_normalized_train,y_equal_normalized_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to print results\n",
    "def get_results(x1):\n",
    "    print(\"\\n{0:30}   {1:4}    {2:4}\".format('Model','Train','Test'))\n",
    "    print('------------------------------------------------')\n",
    "    for i in x1.keys():\n",
    "        print(\"{0:30}   {1:<6.4}   {2:<6.4}\".format(i,x1[i][0],x1[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to store all the results:\n",
    "result_scores = {}\n",
    "# Score the Model on Training and Testing Set\n",
    "result_scores['Logistic_noReg_all'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_all_train,clf_all.predict(X_all_train)),\n",
    "             sklearn.metrics.accuracy_score(y_all_test,clf_all.predict(X_all_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scores['Logistic_noReg_equal'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_equal_train,clf_equal.predict(X_equal_train)),\n",
    "             sklearn.metrics.accuracy_score(y_equal_test,clf_equal.predict(X_equal_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scores['Logistic_noReg_all_norm'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_all_normalized_train,clf_all_normalized.predict(X_all_normalized_train)),\n",
    "             sklearn.metrics.accuracy_score(y_all_normalized_test,clf_all_normalized.predict(X_all_normalized_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scores['Logistic_noReg_equal_norm'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_equal_normalized_train,clf_equal_normalized.predict(X_equal_normalized_train)),\n",
    "             sklearn.metrics.accuracy_score(y_equal_normalized_test,clf_equal_normalized.predict(X_equal_normalized_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                            Train    Test\n",
      "------------------------------------------------\n",
      "Logistic_noReg_all               0.8574   0.8692\n",
      "Logistic_noReg_equal             0.5491   0.5345\n",
      "Logistic_noReg_all_norm          0.854    0.8712\n",
      "Logistic_noReg_equal_norm        0.6569   0.6069\n"
     ]
    }
   ],
   "source": [
    "get_results(result_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
